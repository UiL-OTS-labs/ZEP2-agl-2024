
import condition;

enum TestType {
    TT_NA, // not applicable (trainings items)
    TT_1A,
    TT_1B,
    TT_2A,
    TT_2B,
    TT_3A,
    TT_3B
};

enum ResponseType {
    FIRST,
    SECOND
};


// Item table record.
record TrainItem
{
    int         id;             // item id
    int         block;          // the block of the stimuli 1, 2 or 3
    int         nth_rep;        // the nth rep within the block
    CondEntropy entropy;        // entropy of item
    CondLang    language;       // L1 or L2
    string      sndfn;          // stimulus word sound filename
};

void print_train_items(TrainItem[] items, bool header) {
    int i = 0;
    if (header)
        println("id\tblock\tnth_rep\tentropy\tlanguage\tword");

    while (i < items.size) {
        TrainItem it = items[i];
        println("" + it.id + "\t"
                   + it.block + "\t"
                   + it.nth_rep + "\t"
                   + it.entropy + "\t"
                   + it.language + "\t"
                   + it.sndfn
               );
        i++;
    }
}


/*
 * The training stimuli are presented in these 3 lists, each
 * list corresponds to a block.
 */
TrainItem[] training_items1 = {};
TrainItem[] training_items2 = {};
TrainItem[] training_items3 = {};


// Training items of language 1 with low entropy
TrainItem[] items_low_l1 =
{
    {1 , 1, 1, EN_LOW, LANG_L1, "naf_hog_tep"},
    {2 , 1, 1, EN_LOW, LANG_L1, "naf_nit_tep"},
    {3 , 1, 1, EN_LOW, LANG_L1, "naf_zuk_tep"},
    {4 , 1, 1, EN_LOW, LANG_L1, "wop_hog_bif"},
    {5 , 1, 1, EN_LOW, LANG_L1, "wop_nit_bif"},
    {6 , 1, 1, EN_LOW, LANG_L1, "wop_zuk_bif"},
    {7 , 1, 1, EN_LOW, LANG_L1, "bap_hog_lut"},
    {8 , 1, 1, EN_LOW, LANG_L1, "bap_nit_lut"},
    {9 , 1, 1, EN_LOW, LANG_L1, "bap_zuk_lut"},
    {10, 1, 1, EN_LOW, LANG_L1, "pem_hog_dos"},
    {11, 1, 1, EN_LOW, LANG_L1, "pem_nit_dos"},
    {12, 1, 1, EN_LOW, LANG_L1, "pem_zuk_dos"},
    {13, 1, 1, EN_LOW, LANG_L1, "pem_hog_dos"},
    {14, 1, 1, EN_LOW, LANG_L1, "pem_nit_dos"},
    {15, 1, 1, EN_LOW, LANG_L1, "pem_zuk_dos"},
    {16, 1, 1, EN_LOW, LANG_L1, "pem_hog_dos"},
    {17, 1, 1, EN_LOW, LANG_L1, "pem_nit_dos"},
    {18, 1, 1, EN_LOW, LANG_L1, "pem_zuk_dos"},
    {19, 1, 1, EN_LOW, LANG_L1, "naf_huf_tep"},
    {20, 1, 1, EN_LOW, LANG_L1, "naf_jal_tep"},
    {21, 1, 1, EN_LOW, LANG_L1, "naf_huf_tep"},
    {22, 1, 1, EN_LOW, LANG_L1, "naf_jal_tep"},
    {23, 1, 1, EN_LOW, LANG_L1, "naf_huf_tep"},
    {24, 1, 1, EN_LOW, LANG_L1, "naf_jal_tep"},
    {25, 1, 1, EN_LOW, LANG_L1, "wop_jik_bif"},
    {26, 1, 1, EN_LOW, LANG_L1, "wop_nup_bif"},
    {27, 1, 1, EN_LOW, LANG_L1, "wop_jik_bif"},
    {28, 1, 1, EN_LOW, LANG_L1, "wop_nup_bif"},
    {29, 1, 1, EN_LOW, LANG_L1, "wop_jik_bif"},
    {30, 1, 1, EN_LOW, LANG_L1, "wop_nup_bif"},
    {31, 1, 1, EN_LOW, LANG_L1, "bap_rak_lut"},
    {32, 1, 1, EN_LOW, LANG_L1, "bap_toef_lut"},
    {33, 1, 1, EN_LOW, LANG_L1, "bap_rak_lut"},
    {34, 1, 1, EN_LOW, LANG_L1, "bap_toef_lut"},
    {35, 1, 1, EN_LOW, LANG_L1, "bap_rak_lut"},
    {36, 1, 1, EN_LOW, LANG_L1, "bap_toef_lut"},
    {37, 1, 1, EN_LOW, LANG_L1, "mip_dul_sot"},
    {38, 1, 1, EN_LOW, LANG_L1, "mip_ves_sot"},
    {39, 1, 1, EN_LOW, LANG_L1, "mip_kof_sot"},
    {40, 1, 1, EN_LOW, LANG_L1, "mip_dul_sot"},
    {41, 1, 1, EN_LOW, LANG_L1, "mip_ves_sot"},
    {42, 1, 1, EN_LOW, LANG_L1, "mip_kof_sot"},
    {43, 1, 1, EN_LOW, LANG_L1, "mip_dul_sot"},
    {44, 1, 1, EN_LOW, LANG_L1, "mip_ves_sot"},
    {45, 1, 1, EN_LOW, LANG_L1, "mip_kof_sot"}
};

// Training items of language 1 with high entropy
TrainItem[] items_high_l1 =
{
    {1,  1, 1, EN_HIGH, LANG_L1, "naf_hog_tep"},
    {2,  1, 1, EN_HIGH, LANG_L1, "naf_nit_tep"},
    {3,  1, 1, EN_HIGH, LANG_L1, "naf_zuk_tep"},
    {4,  1, 1, EN_HIGH, LANG_L1, "naf_huf_tep"},
    {5,  1, 1, EN_HIGH, LANG_L1, "naf_jal_tep"},
    {6,  1, 1, EN_HIGH, LANG_L1, "naf_jik_tep"},
    {7,  1, 1, EN_HIGH, LANG_L1, "naf_nup_tep"},
    {8,  1, 1, EN_HIGH, LANG_L1, "naf_rak_tep"},
    {9,  1, 1, EN_HIGH, LANG_L1, "naf_toef_tep"},
    {0,  1, 1, EN_HIGH, LANG_L1, "wop_hog_bif"},
    {11, 1, 1, EN_HIGH, LANG_L1, "wop_nit_bif"},
    {12, 1, 1, EN_HIGH, LANG_L1, "wop_zuk_bif"},
    {13, 1, 1, EN_HIGH, LANG_L1, "wop_huf_bif"},
    {14, 1, 1, EN_HIGH, LANG_L1, "wop_jal_bif"},
    {15, 1, 1, EN_HIGH, LANG_L1, "wop_jik_bif"},
    {16, 1, 1, EN_HIGH, LANG_L1, "wop_nup_bif"},
    {17, 1, 1, EN_HIGH, LANG_L1, "wop_rak_bif"},
    {18, 1, 1, EN_HIGH, LANG_L1, "wop_toef_bif"},
    {19, 1, 1, EN_HIGH, LANG_L1, "bap_hog_lut"},
    {20, 1, 1, EN_HIGH, LANG_L1, "bap_nit_lut"},
    {21, 1, 1, EN_HIGH, LANG_L1, "bap_zuk_lut"},
    {22, 1, 1, EN_HIGH, LANG_L1, "bap_huf_lut"},
    {23, 1, 1, EN_HIGH, LANG_L1, "bap_jal_lut"},
    {24, 1, 1, EN_HIGH, LANG_L1, "bap_jik_lut"},
    {25, 1, 1, EN_HIGH, LANG_L1, "bap_nup_lut"},
    {26, 1, 1, EN_HIGH, LANG_L1, "bap_rak_lut"},
    {27, 1, 1, EN_HIGH, LANG_L1, "bap_toef_lut"},
    {28, 1, 1, EN_HIGH, LANG_L1, "pem_hog_dos"},
    {29, 1, 1, EN_HIGH, LANG_L1, "pem_nit_dos"},
    {30, 1, 1, EN_HIGH, LANG_L1, "pem_zuk_dos"},
    {31, 1, 1, EN_HIGH, LANG_L1, "pem_hog_dos"},
    {32, 1, 1, EN_HIGH, LANG_L1, "pem_nit_dos"},
    {33, 1, 1, EN_HIGH, LANG_L1, "pem_zuk_dos"},
    {34, 1, 1, EN_HIGH, LANG_L1, "pem_hog_dos"},
    {35, 1, 1, EN_HIGH, LANG_L1, "pem_nit_dos"},
    {36, 1, 1, EN_HIGH, LANG_L1, "pem_zuk_dos"},
    {37, 1, 1, EN_HIGH, LANG_L1, "mip_dul_sot"},
    {38, 1, 1, EN_HIGH, LANG_L1, "mip_ves_sot"},
    {39, 1, 1, EN_HIGH, LANG_L1, "mip_kof_sot"},
    {40, 1, 1, EN_HIGH, LANG_L1, "mip_dul_sot"},
    {41, 1, 1, EN_HIGH, LANG_L1, "mip_ves_sot"},
    {42, 1, 1, EN_HIGH, LANG_L1, "mip_kof_sot"},
    {43, 1, 1, EN_HIGH, LANG_L1, "mip_dul_sot"},
    {44, 1, 1, EN_HIGH, LANG_L1, "mip_ves_sot"},
    {45, 1, 1, EN_HIGH, LANG_L1, "mip_kof_sot"}
}

// Training items of language 2 with low entropy
TrainItem[] items_low_l2 =
{
    {1,  1, 1, EN_LOW, LANG_L2, "naf_hog_tep"},
    {2,  1, 1, EN_LOW, LANG_L2, "naf_nit_tep"},
    {3,  1, 1, EN_LOW, LANG_L2, "naf_zuk_tep"},
    {4,  1, 1, EN_LOW, LANG_L2, "naf_huf_tep"},
    {5,  1, 1, EN_LOW, LANG_L2, "naf_jal_tep"},
    {6,  1, 1, EN_LOW, LANG_L2, "naf_huf_tep"},
    {7,  1, 1, EN_LOW, LANG_L2, "naf_jal_tep"},
    {8,  1, 1, EN_LOW, LANG_L2, "naf_huf_tep"},
    {9,  1, 1, EN_LOW, LANG_L2, "naf_jal_tep"},
    {10, 1, 1, EN_LOW, LANG_L2, "wop_hog_bif"},
    {11, 1, 1, EN_LOW, LANG_L2, "wop_nit_bif"},
    {12, 1, 1, EN_LOW, LANG_L2, "wop_zuk_bif"},
    {13, 1, 1, EN_LOW, LANG_L2, "wop_jik_bif"},
    {14, 1, 1, EN_LOW, LANG_L2, "wop_nup_bif"},
    {15, 1, 1, EN_LOW, LANG_L2, "wop_jik_bif"},
    {16, 1, 1, EN_LOW, LANG_L2, "wop_nup_bif"},
    {17, 1, 1, EN_LOW, LANG_L2, "wop_jik_bif"},
    {18, 1, 1, EN_LOW, LANG_L2, "wop_nup_bif"},
    {19, 1, 1, EN_LOW, LANG_L2, "bap_hog_lut"},
    {20, 1, 1, EN_LOW, LANG_L2, "bap_nit_lut"},
    {21, 1, 1, EN_LOW, LANG_L2, "bap_zuk_lut"},
    {22, 1, 1, EN_LOW, LANG_L2, "bap_rak_lut"},
    {23, 1, 1, EN_LOW, LANG_L2, "bap_toef_lut"},
    {24, 1, 1, EN_LOW, LANG_L2, "bap_rak_lut"},
    {25, 1, 1, EN_LOW, LANG_L2, "bap_toef_lut"},
    {26, 1, 1, EN_LOW, LANG_L2, "bap_rak_lut"},
    {27, 1, 1, EN_LOW, LANG_L2, "bap_toef_lut"},
    {28, 1, 1, EN_LOW, LANG_L2, "mip_hog_sot"},
    {29, 1, 1, EN_LOW, LANG_L2, "mip_nit_sot"},
    {30, 1, 1, EN_LOW, LANG_L2, "mip_zuk_sot"},
    {31, 1, 1, EN_LOW, LANG_L2, "mip_hog_sot"},
    {32, 1, 1, EN_LOW, LANG_L2, "mip_nit_sot"},
    {33, 1, 1, EN_LOW, LANG_L2, "mip_zuk_sot"},
    {34, 1, 1, EN_LOW, LANG_L2, "mip_hog_sot"},
    {35, 1, 1, EN_LOW, LANG_L2, "mip_nit_sot"},
    {36, 1, 1, EN_LOW, LANG_L2, "mip_zuk_sot"},
    {37, 1, 1, EN_LOW, LANG_L2, "pem_dul_dos"},
    {38, 1, 1, EN_LOW, LANG_L2, "pem_ves_dos"},
    {39, 1, 1, EN_LOW, LANG_L2, "pem_kof_dos"},
    {40, 1, 1, EN_LOW, LANG_L2, "pem_dul_dos"},
    {41, 1, 1, EN_LOW, LANG_L2, "pem_ves_dos"},
    {42, 1, 1, EN_LOW, LANG_L2, "pem_kof_dos"},
    {43, 1, 1, EN_LOW, LANG_L2, "pem_dul_dos"},
    {44, 1, 1, EN_LOW, LANG_L2, "pem_ves_dos"},
    {45, 1, 1, EN_LOW, LANG_L2, "pem_kof_dos"}
};


// Training items of language 2 with high entropy
TrainItem[] items_high_l2 =
{
    {1,  1, 1, EN_HIGH, LANG_L2, "naf_hog_tep"},
    {2,  1, 1, EN_HIGH, LANG_L2, "naf_nit_tep"},
    {3,  1, 1, EN_HIGH, LANG_L2, "naf_zuk_tep"},
    {4,  1, 1, EN_HIGH, LANG_L2, "naf_huf_tep"},
    {1,  1, 1, EN_HIGH, LANG_L2, "naf_jal_tep"},
    {6,  1, 1, EN_HIGH, LANG_L2, "naf_jik_tep"},
    {7,  1, 1, EN_HIGH, LANG_L2, "naf_nup_tep"},
    {8,  1, 1, EN_HIGH, LANG_L2, "naf_rak_tep"},
    {9,  1, 1, EN_HIGH, LANG_L2, "naf_toef_tep"},
    {0,  1, 1, EN_HIGH, LANG_L2, "wop_hog_bif"},
    {11, 1, 1, EN_HIGH, LANG_L2, "wop_nit_bif"},
    {12, 1, 1, EN_HIGH, LANG_L2, "wop_zuk_bif"},
    {13, 1, 1, EN_HIGH, LANG_L2, "wop_huf_bif"},
    {14, 1, 1, EN_HIGH, LANG_L2, "wop_jal_bif"},
    {11, 1, 1, EN_HIGH, LANG_L2, "wop_jik_bif"},
    {16, 1, 1, EN_HIGH, LANG_L2, "wop_nup_bif"},
    {17, 1, 1, EN_HIGH, LANG_L2, "wop_rak_bif"},
    {18, 1, 1, EN_HIGH, LANG_L2, "wop_toef_bif"},
    {19, 1, 1, EN_HIGH, LANG_L2, "bap_hog_lut"},
    {20, 1, 1, EN_HIGH, LANG_L2, "bap_nit_lut"},
    {21, 1, 1, EN_HIGH, LANG_L2, "bap_zuk_lut"},
    {22, 1, 1, EN_HIGH, LANG_L2, "bap_huf_lut"},
    {23, 1, 1, EN_HIGH, LANG_L2, "bap_jal_lut"},
    {24, 1, 1, EN_HIGH, LANG_L2, "bap_jik_lut"},
    {21, 1, 1, EN_HIGH, LANG_L2, "bap_nup_lut"},
    {26, 1, 1, EN_HIGH, LANG_L2, "bap_rak_lut"},
    {27, 1, 1, EN_HIGH, LANG_L2, "bap_toef_lut"},
    {28, 1, 1, EN_HIGH, LANG_L2, "mip_hog_sot"},
    {29, 1, 1, EN_HIGH, LANG_L2, "mip_nit_sot"},
    {30, 1, 1, EN_HIGH, LANG_L2, "mip_zuk_sot"},
    {31, 1, 1, EN_HIGH, LANG_L2, "mip_hog_sot"},
    {32, 1, 1, EN_HIGH, LANG_L2, "mip_nit_sot"},
    {33, 1, 1, EN_HIGH, LANG_L2, "mip_zuk_sot"},
    {34, 1, 1, EN_HIGH, LANG_L2, "mip_hog_sot"},
    {31, 1, 1, EN_HIGH, LANG_L2, "mip_nit_sot"},
    {36, 1, 1, EN_HIGH, LANG_L2, "mip_zuk_sot"},
    {37, 1, 1, EN_HIGH, LANG_L2, "pem_dul_dos"},
    {38, 1, 1, EN_HIGH, LANG_L2, "pem_ves_dos"},
    {39, 1, 1, EN_HIGH, LANG_L2, "pem_kof_dos"},
    {40, 1, 1, EN_HIGH, LANG_L2, "pem_dul_dos"},
    {41, 1, 1, EN_HIGH, LANG_L2, "pem_ves_dos"},
    {42, 1, 1, EN_HIGH, LANG_L2, "pem_kof_dos"},
    {43, 1, 1, EN_HIGH, LANG_L2, "pem_dul_dos"},
    {44, 1, 1, EN_HIGH, LANG_L2, "pem_ves_dos"},
    {45, 1, 1, EN_HIGH, LANG_L2, "pem_kof_dos"},
}

void append_train_item(TrainItem[] array, TrainItem item) {
    array.size = array.size + 1;
    array[array.size - 1] = item;
}

void append_test_item(TestItem[] array, TestItem item) {
    array.size = array.size + 1;
    array[array.size - 1] = item;
}

// No two subsequent items should have the same sound file.
bool
check_train_items(TrainItem[] input) {
    int i = 1;
    while (i < input.size) {
        if (input[i].sndfn == input[i-1].sndfn)
            return false;
        i++;
    }
    if (input.size != 90) {
        print_error("Oops the training item block doesn't contain 90 items.\n");
    }
    return input.size == 90;
}

// Puts the 45 train items in a randomized fashion in the block twice. So
// The final block will contain 90 items
bool
train_items_append_block(TrainItem[] output, TrainItem[] input, int block) {

    bool meets_constraints = false;
    int num_tries = 1000;
    int num = 0;

    while (!meets_constraints && num < num_tries) {
        int i = 0;
        output.size = 0;

        input.shuffle(0, -1);
        while (i < input.size) {
            TrainItem item = input[i];
            item.block = block;
            append_train_item(output, item);
            i++;
        }

        i = 0;
        input.shuffle(0, -1);
        while (i < input.size) {
            TrainItem item = input[i];
            item.block = block;
            append_train_item(output, item);
            i++;
        }
        num++;
        meets_constraints = check_train_items(output);
    }

    return meets_constraints;
}

// If we only had associative arrays...
void
count_repetitions(TrainItem[] items)
{
    int i = 0;
    while (i < items.size) {
        string needle = items[i].sndfn;
        int j = 0;
        int num_found = 0;
        while (j <= i) { // Count the needle too.
            if (needle == items[j].sndfn) {
                num_found++;
            }
            j++;
        }
        items[i].nth_rep = num_found;
        i++;
    }
}

/*
 * Distributes all training items over the three separate lists/blocks
 */
void prepare_training_lists(TrainItem[] input) {
    train_items_append_block(training_items1, input, 1);
    train_items_append_block(training_items2, input, 2);
    train_items_append_block(training_items3, input, 3);
    count_repetitions(training_items1);
    count_repetitions(training_items2);
    count_repetitions(training_items3);
}

/*
 * Selects the right source list for the current conditions and
 * prepares the training lists.
 */
void prepare_training_items()
{
    TrainItem[] training_items;

    if (chosen_entropy == EN_HIGH) {
        if (chosen_language == LANG_L1)
            training_items = items_high_l1;
        else 
            training_items = items_high_l2;
    }
    else {
        if (chosen_language == LANG_L1)
            training_items = items_low_l1;
        else
            training_items = items_low_l2;
    }

    prepare_training_lists(training_items);
}

/*
 * Test items
 */
record TestItem {
    int         id;
    TestType    type;
    string      fn;
};

void print_test_item(TestItem item) {
    println(string(item.id)   + " " +
            string(item.type) + " " +
            item.fn
            );
}

void print_test_items(TestItem[] items, bool header) {
    int i = 0;
    if (header)
        println("id list_ab grammar1 file1 gramar2 file2");

    while (i < items.size) {
        print_test_item(items[i]);
        i++;
    }
}

// Test items L1
TestItem[] test_items_l1_3a = {
    {1, TT_3A, "3a.naf_hog_tep"},
    {2, TT_3A, "3a.naf_nit_tep"},
    {3, TT_3A, "3a.wop_hog_bif"},
    {4, TT_3A, "3a.wop_nit_bif"},
    {5, TT_3A, "3a.bap_hog_lut"},
    {6, TT_3A, "3a.bap_nit_lut"},
};

TestItem[] test_items_l1_3b = {
    {1, TT_3B, "3b.hog_bif_wop"},
    {2, TT_3B, "3b.nit_lut_bap"},
    {3, TT_3B, "3b.zuk_tep_naf"},
    {4, TT_3B, "3b.tep_naf_hog"},
    {5, TT_3B, "3b.bif_wop_nit"},
    {6, TT_3B, "3b.lut_bap_zuk"},
};

TestItem[] test_items_l1_1a = {
    {1, TT_1A, "1a.pem_huf_dos"},
    {2, TT_1A, "1a.pem_jal_dos"},
    {3, TT_1A, "1a.pem_jik_dos"},
    {4, TT_1A, "1a.pem_nup_dos"},
    {5, TT_1A, "1a.pem_rak_dos"},
    {6, TT_1A, "1a.pem_toef_dos"},
};

TestItem[] test_items_l1_1b = {
    {1, TT_1B, "1b.mip_huf_sot"},
    {2, TT_1B, "1b.mip_jal_sot"},
    {3, TT_1B, "1b.mip_jik_sot"},
    {4, TT_1B, "1b.mip_nup_sot"},
    {5, TT_1B, "1b.mip_rak_sot"},
    {6, TT_1B, "1b.mip_toef_sot"},
};

TestItem[] test_items_l1_2a = {
    {1, TT_2A, "2a.pem_bug_dos"},
    {2, TT_2A, "2a.pem_gak_dos"},
    {3, TT_2A, "2a.pem_zim_dos"},
    {4, TT_2A, "2a.naf_bug_tep"},
    {5, TT_2A, "2a.naf_gak_tep"},
    {6, TT_2A, "2a.naf_zim_tep"},
};

TestItem[] test_items_l1_2b = {
    {1, TT_2B, "2b.pem_dul_dos"},
    {2, TT_2B, "2b.pem_ves_dos"},
    {3, TT_2B, "2b.pem_kof_dos"},
    {4, TT_2B, "2b.naf_dul_tep"},
    {5, TT_2B, "2b.naf_ves_tep"},
    {6, TT_2B, "2b.naf_kof_tep"},
};

// Test items L2
TestItem[] test_items_l2_1a = {
    {1, TT_1A, "1a.mip_huf_sot"},
    {2, TT_1A, "1a.mip_jal_sot"},
    {3, TT_1A, "1a.mip_jik_sot"},
    {4, TT_1A, "1a.mip_nup_sot"},
    {5, TT_1A, "1a.mip_rak_sot"},
    {6, TT_1A, "1a.mip_toef_sot"},
};

TestItem[] test_items_l2_1b = {
    {1, TT_1B, "1b.pem_huf_dos"},
    {2, TT_1B, "1b.pem_jal_dos"},
    {3, TT_1B, "1b.pem_jik_dos"},
    {4, TT_1B, "1b.pem_nup_dos"},
    {5, TT_1B, "1b.pem_rak_dos"},
    {6, TT_1B, "1b.pem_toef_dos"},
};

TestItem[] test_items_l2_2a = {
    {1, TT_2A, "2a.mip_bug_sot"},
    {2, TT_2A, "2a.mip_gak_sot"},
    {3, TT_2A, "2a.mip_zim_sot"},
    {4, TT_2A, "2a.naf_bug_tep"},
    {5, TT_2A, "2a.naf_gak_tep"},
    {6, TT_2A, "2a.naf_zim_tep"},
};

TestItem[] test_items_l2_2b = {
    {1, TT_2B, "2b.mip_dul_sot"},
    {2, TT_2B, "2b.mip_ves_sot"},
    {3, TT_2B, "2b.mip_kof_sot"},
    {4, TT_2B, "2b.naf_dul_tep"},
    {5, TT_2B, "2b.naf_ves_tep"},
    {6, TT_2B, "2b.naf_kof_tep"},
};

TestItem[] test_items_l2_3a = {
    {1, TT_3A, "3a.naf_hog_tep"},
    {2, TT_3A, "3a.naf_nit_tep"},
    {3, TT_3A, "3a.wop_hog_bif"},
    {4, TT_3A, "3a.wop_nit_bif"},
    {5, TT_3A, "3a.bap_hog_lut"},
    {6, TT_3A, "3a.bap_nit_lut"},
};

TestItem[] test_items_l2_3b = {
    {1, TT_3B, "3b.hog_bif_wop"},
    {2, TT_3B, "3b.nit_lut_bap"},
    {3, TT_3B, "3b.zuk_tep_naf"},
    {4, TT_3B, "3b.tep_naf_hog"},
    {5, TT_3B, "3b.bif_wop_nit"},
    {6, TT_3B, "3b.lut_bap_zuk"},
};

/*The test items above are going to be distributed of the lists below*/ 
TestItem [] test_items1 = {};
TestItem [] test_items2 = {};
TestItem [] test_items3 = {};

TestItem
pop_test_item(TestItem[] stack) {
    TestItem ret = stack[stack.size - 1];
    stack.size = stack.size -1;
    return ret;
}

void 
balance_test_a(TestItem[] output)
{
    if (chosen_language == LANG_L1) {
        append_test_item(output, pop_test_item(test_items_l1_1a));
        append_test_item(output, pop_test_item(test_items_l1_1a));
        append_test_item(output, pop_test_item(test_items_l1_1b));
        append_test_item(output, pop_test_item(test_items_l1_1b));
        
        append_test_item(output, pop_test_item(test_items_l1_2a));
        append_test_item(output, pop_test_item(test_items_l1_2a));
        append_test_item(output, pop_test_item(test_items_l1_2b));
        append_test_item(output, pop_test_item(test_items_l1_2b));
        
        append_test_item(output, pop_test_item(test_items_l1_3a));
        append_test_item(output, pop_test_item(test_items_l1_3a));
        append_test_item(output, pop_test_item(test_items_l1_3b));
        append_test_item(output, pop_test_item(test_items_l1_3b));
    }
    else {
        append_test_item(output, pop_test_item(test_items_l2_1a));
        append_test_item(output, pop_test_item(test_items_l2_1a));
        append_test_item(output, pop_test_item(test_items_l2_1b));
        append_test_item(output, pop_test_item(test_items_l2_1b));
        
        append_test_item(output, pop_test_item(test_items_l2_2a));
        append_test_item(output, pop_test_item(test_items_l2_2a));
        append_test_item(output, pop_test_item(test_items_l2_2b));
        append_test_item(output, pop_test_item(test_items_l2_2b));
        
        append_test_item(output, pop_test_item(test_items_l2_3a));
        append_test_item(output, pop_test_item(test_items_l2_3a));
        append_test_item(output, pop_test_item(test_items_l2_3b));
        append_test_item(output, pop_test_item(test_items_l2_3b));
    }
    output.shuffle(0, 4);
    output.shuffle(4, 8);
    output.shuffle(8, 12);
}

void
balance_test_b(TestItem[] output)
{
    if (chosen_language == LANG_L1) {
        append_test_item(output, pop_test_item(test_items_l1_2a));
        append_test_item(output, pop_test_item(test_items_l1_2a));
        append_test_item(output, pop_test_item(test_items_l1_2b));
        append_test_item(output, pop_test_item(test_items_l1_2b));
        
        append_test_item(output, pop_test_item(test_items_l1_1a));
        append_test_item(output, pop_test_item(test_items_l1_1a));
        append_test_item(output, pop_test_item(test_items_l1_1b));
        append_test_item(output, pop_test_item(test_items_l1_1b));
        
        append_test_item(output, pop_test_item(test_items_l1_3a));
        append_test_item(output, pop_test_item(test_items_l1_3a));
        append_test_item(output, pop_test_item(test_items_l1_3b));
        append_test_item(output, pop_test_item(test_items_l1_3b));
    }
    else {
        append_test_item(output, pop_test_item(test_items_l2_2a));
        append_test_item(output, pop_test_item(test_items_l2_2a));
        append_test_item(output, pop_test_item(test_items_l2_2b));
        append_test_item(output, pop_test_item(test_items_l2_2b));
        
        append_test_item(output, pop_test_item(test_items_l2_1a));
        append_test_item(output, pop_test_item(test_items_l2_1a));
        append_test_item(output, pop_test_item(test_items_l2_1b));
        append_test_item(output, pop_test_item(test_items_l2_1b));
        
        append_test_item(output, pop_test_item(test_items_l2_3a));
        append_test_item(output, pop_test_item(test_items_l2_3a));
        append_test_item(output, pop_test_item(test_items_l2_3b));
        append_test_item(output, pop_test_item(test_items_l2_3b));
    }
    output.shuffle(0, 4);
    output.shuffle(4, 8);
    output.shuffle(8, 12);
}

/*
 * prepares the testitems
 */
void
prepare_test_stims() {
    if (chosen_cb_order == CBA) {
        balance_test_a(test_items1);
        balance_test_a(test_items2);
        balance_test_a(test_items3);
    }
    else if (chosen_cb_order == CBB) {
        balance_test_b(test_items1);
        balance_test_b(test_items2);
        balance_test_b(test_items3);
    }
    else {
        print_error("Unexpected counter balance order");
    }
}

/*
 * Prepares the list for the three test blocks.
 */
void prepare_test_lists () {

    // shuffle the order of the test items.
    // TODO shuffle all test items

    test_items_l1_1a.shuffle(0,-1);
    test_items_l1_1b.shuffle(0,-1);
    test_items_l1_2a.shuffle(0,-1);
    test_items_l1_2b.shuffle(0,-1);
    test_items_l1_3a.shuffle(0,-1);
    test_items_l1_3b.shuffle(0,-1);
    
    test_items_l2_1a.shuffle(0,-1);
    test_items_l2_1b.shuffle(0,-1);
    test_items_l2_2a.shuffle(0,-1);
    test_items_l2_2b.shuffle(0,-1);
    test_items_l2_3a.shuffle(0,-1);
    test_items_l2_3b.shuffle(0,-1);

    prepare_test_stims();
}
